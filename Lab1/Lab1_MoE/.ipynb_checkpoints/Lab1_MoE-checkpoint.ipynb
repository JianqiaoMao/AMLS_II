{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Mixtures of Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how mixtures of experts can be used to boost performance.\n",
    "\n",
    "The objective of this lab is to classify images from Cifar10 (https://www.cs.toronto.edu/~kriz/cifar.html) to one of ten classes: {0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cifar10](cifar10_resize.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, a gating function is trained to pass examples to two experts which are trained separatly, where one expert is trained to classify images within the \"natural image\" category (e.g. cat, dog, etc) and another to classify images within the  \"artificial image\" category (e.g. plane, car). The experts are then used to boost the performance of a baseline architecture that classifies image to one of the 10 classes.\n",
    "\n",
    "Specifically, the mixture is built in the following order:\n",
    "1. A single model is trained to to classify all 10 classes. (This is included in the mixture, and is also our evaluation benchmark)\n",
    "\n",
    "2. An expert gating function is trained to recognise whether an image is of an artificial or  natural subject.\n",
    "\n",
    "3. An artificial expert is trained to classify artificial objects that have a label in {0, 1, 8, 9}.\n",
    "\n",
    "4. A natural expert is trained to classify natural objects that have a label in  {2, 3, 4, 5, 6, 7}.\n",
    "\n",
    "5. A gating function is trained to determine the contribution of the experts and the contribution of the baseline architecture to the final output.\n",
    "\n",
    "6. The mixture is built as illustrated in the figure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](moe_architecture_illus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate, Lambda, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pydot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters (not to be changed)\n",
    "orig_classes = 10 ; gate0_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Parameters\n",
    "\n",
    "You can try changing the mixture parameters in the following piece of code, when doing so, consider the following:\n",
    "\n",
    "1 - Increasing the number of epochs increases the fit to training data, at some point this should cause over-fitting. Conversly, setting it low should cause under-fitting.\n",
    "\n",
    "2 - Increasing the number of training examples increases the number of learnable features.\n",
    "\n",
    "3 - Using a large model for different classifiers increases their capacity to learn. This increases the amount of required epochs for training, and also increases the risk of over-fitting.\n",
    "\n",
    "By changing the parameters, the performance of the mixture of experts and the baseline classifier should change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of training/testing examples per batch\n",
    "batch_size = 50\n",
    "\n",
    "# Training epochs. A higher number of epochs corresponds to \"more fitting to training data\"\n",
    "epochs = 1\n",
    "\n",
    "# Number of training/testing examples to use\n",
    "train_examples = 5000 # Max is 50000\n",
    "test_examples = 1000   # Max is 5000\n",
    "\n",
    "# Large/small model flags. Set to true to change a classifier to \"large\"\n",
    "use_large_experts = False\n",
    "use_large_gating_mlp = False\n",
    "use_large_baseline_classifier = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete previous model checkpoints\n",
    "import shutil\n",
    "shutil.rmtree('gate0Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('moe3Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('natureCifar10', ignore_errors=True)\n",
    "shutil.rmtree('baseCifar10', ignore_errors=True)\n",
    "shutil.rmtree('artCifar10', ignore_errors=True)\n",
    "\n",
    "# get the newest model file within a directory\n",
    "def getNewestModel(model, dirname):\n",
    "    from glob import glob\n",
    "    target = os.path.join(dirname, '*')\n",
    "    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n",
    "    if len(files) == 0:\n",
    "        return model\n",
    "    else:\n",
    "        newestModel = sorted(files, key=lambda files: files[1])[-1]\n",
    "        model.load_weights(newestModel[0])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset  ; X: input images,  Y: class label ground truth\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train[:train_examples] ; x_test = x_test[:test_examples]\n",
    "y_train = y_train[:train_examples] ; y_test = y_test[:test_examples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare x dataset\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train0:(5000, 10)\n",
      "y test0:(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train0 = keras.utils.to_categorical(y_train, orig_classes)\n",
    "y_test0 = keras.utils.to_categorical(y_test, orig_classes)\n",
    "\n",
    "print(\"y train0:{0}\\ny test0:{1}\".format(y_train0.shape, y_test0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input layer\n",
    "cifarInput = Input(shape=(x_train.shape[1:]), name=\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small VGG-like model\n",
    "def simpleVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(12)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[8])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[9])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[10])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[11])(vgg)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Large VGG-like model\n",
    "def fatVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(17)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[8])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[9])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[10])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[11])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[12])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[13])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[14])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[15])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[16])(vgg)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first gating network, to decide artificial or natural object\n",
    "if use_large_gating_mlp:\n",
    "    gate0VGG = fatVGG(cifarInput, gate0_classes, \"gate0\")\n",
    "else:\n",
    "    gate0VGG = simpleVGG(cifarInput, gate0_classes, \"gate0\")\n",
    "gate0Model = Model(cifarInput, gate0VGG)\n",
    "\n",
    "# base VGG\n",
    "if use_large_baseline_classifier:\n",
    "    baseVGG = fatVGG(cifarInput, orig_classes, \"base\")\n",
    "else:\n",
    "    baseVGG = simpleVGG(cifarInput, orig_classes, \"base\") \n",
    "baseModel = Model(cifarInput, baseVGG)\n",
    "\n",
    "# artificial expert VGG\n",
    "if use_large_experts:\n",
    "    artificialVGG = fatVGG(cifarInput, orig_classes, \"artificial\")\n",
    "else:\n",
    "    artificialVGG = simpleVGG(cifarInput, orig_classes, \"artificial\")\n",
    "artificialModel = Model(cifarInput, artificialVGG)\n",
    "\n",
    "# naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "if use_large_experts:\n",
    "    naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "else:\n",
    "    naturalVGG = simpleVGG(cifarInput, orig_classes, \"natural\")\n",
    "\n",
    "naturalModel = Model(cifarInput, naturalVGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 10-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "baseModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make saving directory for checkpoints\n",
    "baseSaveDir = \"./baseCifar10/\"\n",
    "if not os.path.isdir(baseSaveDir):\n",
    "    os.makedirs(baseSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(baseSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 2.0810 - acc: 0.2176 - val_loss: 1.7643 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.76427, saving model to ./baseCifar10/Cifar10_.01-1.76.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07d28b00b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "baseModel.fit(x_train, y_train0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_test0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 515us/step\n",
      "[1.7642748794555665, 0.364]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)\n",
    "baseScore = baseModel.evaluate(x_test, y_test0)\n",
    "print(baseScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train 2-Class Natural/Artificial Classifier\n",
    "\n",
    "The expert gating model determines whether an image is \"natural\" or \"artificial\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y trainG0:(5000, 2)\n",
      "y testG0:(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make ground truth for whether an example is \"natural\" or \"artificial\"\n",
    "y_trainG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_train])\n",
    "y_testG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_test])\n",
    "\n",
    "y_trainG0 = keras.utils.to_categorical(y_trainG0, 2)\n",
    "y_testG0  = keras.utils.to_categorical(y_testG0, 2)\n",
    "\n",
    "print(\"y trainG0:{0}\\ny testG0:{1}\".format(y_trainG0.shape, y_testG0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "gate0Model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "gate0SaveDir = \"./gate0Cifar10/\"\n",
    "if not os.path.isdir(gate0SaveDir):\n",
    "    os.makedirs(gate0SaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(gate0SaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 0.4830 - acc: 0.7716 - val_loss: 0.3297 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32965, saving model to ./gate0Cifar10/Cifar10_.01-0.33.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f075c6aeda0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "gate0Model.fit(x_train, y_trainG0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_testG0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 480us/step\n",
      "[0.32965031695365904, 0.86]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)\n",
    "gate0Score = gate0Model.evaluate(x_test, y_testG0)\n",
    "print(gate0Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"Natural\" and \"Artificial\" Experts\n",
    "<br>\n",
    "The expert networks are specialized in predicting a certain classes.<br>\n",
    "Each network is only trained with its specialized field: the artificial expert get trained for labels 0, 1, 8 and 9; the natural expert for labels 2, 3, 4, 5, 6 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the position of artificial images and natural images in training and test dataset\n",
    "artTrain = [i for i in range(len(y_train)) if y_train[i] in [0,1,8,9]]\n",
    "natureTrain = [i for i in range(len(y_train)) if y_train[i] in [2,3,4,5,6,7]]\n",
    "artTest = [i for i in range(len(y_test)) if y_test[i] in [0,1,8,9]]\n",
    "natureTest = [i for i in range(len(y_test)) if y_test[i] in [2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get artificial dataset and natural dataset\n",
    "x_trainArt = x_train[artTrain]\n",
    "x_testArt = x_test[artTest]\n",
    "y_trainArt = y_train[artTrain]\n",
    "y_testArt = y_test[artTest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train art:(1983, 10)\n",
      "y test art:(407, 10)\n"
     ]
    }
   ],
   "source": [
    "# for artificial dataset\n",
    "y_trainArt = keras.utils.to_categorical(y_trainArt, orig_classes)\n",
    "y_testArt = keras.utils.to_categorical(y_testArt, orig_classes)\n",
    "\n",
    "print(\"y train art:{0}\\ny test art:{1}\".format(y_trainArt.shape, y_testArt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "artificialModel.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Adam(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "artSaveDir = \"./artCifar10/\"\n",
    "if not os.path.isdir(artSaveDir):\n",
    "    os.makedirs(artSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(artSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1983 samples, validate on 407 samples\n",
      "Epoch 1/1\n",
      "1983/1983 [==============================] - 5s 2ms/step - loss: 1.4016 - acc: 0.3399 - val_loss: 1.1364 - val_acc: 0.5283\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13642, saving model to ./artCifar10/Cifar10_.01-1.14.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f075c7c2128>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "artificialModel.fit(x_trainArt, y_trainArt,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testArt, y_testArt),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 469us/step\n",
      "[1.1364187166204616, 0.5282555279626308]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)\n",
    "artScore = artificialModel.evaluate(x_testArt, y_testArt)\n",
    "print(artScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Natural expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for natural dataset\n",
    "x_trainNat = x_train[natureTrain]\n",
    "x_testNat = x_test[natureTest]\n",
    "y_trainNat = y_train[natureTrain]\n",
    "y_testNat = y_test[natureTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train nature:(3017, 10)\n",
      "y test nature:(593, 10)\n"
     ]
    }
   ],
   "source": [
    "# get natural dataset\n",
    "y_trainNat = keras.utils.to_categorical(y_trainNat, orig_classes)\n",
    "y_testNat = keras.utils.to_categorical(y_testNat, orig_classes)\n",
    "\n",
    "print(\"y train nature:{0}\\ny test nature:{1}\".format(y_trainNat.shape, y_testNat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "naturalModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "natSaveDir = \"./natureCifar10/\"\n",
    "if not os.path.isdir(natSaveDir):\n",
    "    os.makedirs(natSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(natSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3017 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "3017/3017 [==============================] - 7s 2ms/step - loss: 1.8203 - acc: 0.2294 - val_loss: 1.6741 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.67409, saving model to ./natureCifar10/Cifar10_.01-1.67.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f075044dda0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "naturalModel.fit(x_trainNat, y_trainNat,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testNat, y_testNat),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 0s 471us/step\n",
      "[1.6740850533844045, 0.3541315345951116]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)\n",
    "natScore = naturalModel.evaluate(x_testNat, y_testNat)\n",
    "print(natScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the weights of all trained models so far (i.e. baseline, experts, and expert gating models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in baseModel.layers:\n",
    "    l.trainable = False\n",
    "for l in gate0Model.layers:\n",
    "    l.trainable = False\n",
    "for l in artificialModel.layers:\n",
    "    l.trainable = False\n",
    "for l in naturalModel.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Connecting the overall networks to form the mixture of experts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define sub-Gate network, for the second gating network layer\n",
    "def subGate(cifarInput, orig_classes, numExperts, name=\"subGate\"):\n",
    "    name = [name+str(i) for i in range(5)]\n",
    "    subgate = Flatten(name=name[0])(cifarInput)\n",
    "    subgate = Dense(512, activation='relu', name=name[1])(subgate)\n",
    "    subgate = Dropout(0.5, name=name[2])(subgate)\n",
    "    subgate = Dense(orig_classes*numExperts, activation='softmax', name=name[3])(subgate)\n",
    "    subgate = Reshape((orig_classes, numExperts), name=name[4])(subgate)\n",
    "    return subgate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the artificial gating network\n",
    "artGate = subGate(cifarInput, orig_classes, 2, \"artExpertGate\")\n",
    "\n",
    "# the natural gating network\n",
    "natureGate = subGate(cifarInput, orig_classes, 2, \"natureExpertGate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define inference calculation with Keras Lambda layer with base VGG, expert network and the second gating network of corresponding expert as input\n",
    "# the inference is calculated as sum of multiplications of base VGG inference output and its importance, and expert network inference output and its importance\n",
    "def subGateLambda(base, expert, subgate):\n",
    "    output = Lambda(lambda gx: (gx[0]*gx[2][:,:,0]) + (gx[1]*gx[2][:,:,1]), output_shape=(orig_classes,))([base, expert, subgate])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connecting the overall networks.\n",
    "# the Keras backend switch works as deciding with the first gating network, leading to artificial or natural gate\n",
    "output = Lambda(lambda gx: K.switch(gx[1][:,0] > gx[1][:,1], \n",
    "                                    subGateLambda(gx[0], gx[2], gx[4]), \n",
    "                                    subGateLambda(gx[0], gx[3], gx[5])), \n",
    "                output_shape=(orig_classes,))([baseVGG, gate0VGG, artificialVGG, naturalVGG, artGate, natureGate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the mixture of experts model\n",
    "model = Model(cifarInput, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f076ab6deb8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f07683ed978> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f076ab6dc18> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d2da860> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d175668> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f07683599b0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f07cc6e5b38> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d2a2cf8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d142898> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f07682f7668> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f07cef34828> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f075d26e0f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f075d0e41d0> False\n",
      "<keras.layers.core.Dropout object at 0x7f07682f7630> False\n",
      "<keras.layers.core.Dropout object at 0x7f076ab45128> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d26e160> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d0e4e10> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f07682f7710> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f076ab45710> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d26e128> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d0e4b70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f07683316a0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0786d292b0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d2095c0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f075d0a70f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f075d34f470> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f07684624e0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f075d1c7a90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f075d0714a8> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d34f438> False\n",
      "<keras.layers.core.Dropout object at 0x7f07684624a8> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d1ea1d0> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d071f98> False\n",
      "<keras.layers.core.Flatten object at 0x7f07382ffa90> True\n",
      "<keras.layers.core.Flatten object at 0x7f07382ffe80> True\n",
      "<keras.layers.core.Flatten object at 0x7f075d34f518> False\n",
      "<keras.layers.core.Flatten object at 0x7f0768462588> False\n",
      "<keras.layers.core.Flatten object at 0x7f075d1ea0b8> False\n",
      "<keras.layers.core.Flatten object at 0x7f075d071f60> False\n",
      "<keras.layers.core.Dense object at 0x7f07503a7b00> True\n",
      "<keras.layers.core.Dense object at 0x7f0738311dd8> True\n",
      "<keras.layers.core.Dense object at 0x7f075d30a630> False\n",
      "<keras.layers.core.Dense object at 0x7f0768404358> False\n",
      "<keras.layers.core.Dense object at 0x7f075d18b6d8> False\n",
      "<keras.layers.core.Dense object at 0x7f075d00f400> False\n",
      "<keras.layers.core.Dropout object at 0x7f07502fe0f0> True\n",
      "<keras.layers.core.Dropout object at 0x7f07382a7240> True\n",
      "<keras.layers.core.Dropout object at 0x7f075d328a90> False\n",
      "<keras.layers.core.Dropout object at 0x7f07683befd0> False\n",
      "<keras.layers.core.Dropout object at 0x7f075d152550> False\n",
      "<keras.layers.core.Dropout object at 0x7f075cfd6fd0> False\n",
      "<keras.layers.core.Dense object at 0x7f07502fe9e8> True\n",
      "<keras.layers.core.Dense object at 0x7f07382a7550> True\n",
      "<keras.layers.core.Dense object at 0x7f075d328c50> False\n",
      "<keras.layers.core.Dense object at 0x7f07683beb38> False\n",
      "<keras.layers.core.Dense object at 0x7f075d152710> False\n",
      "<keras.layers.core.Dense object at 0x7f075cfd6f28> False\n",
      "<keras.layers.core.Reshape object at 0x7f0738311908> True\n",
      "<keras.layers.core.Reshape object at 0x7f07382504a8> True\n",
      "<keras.layers.core.Lambda object at 0x7f07381c3eb8> True\n"
     ]
    }
   ],
   "source": [
    "# show layers and if it's trainable or not\n",
    "# only the second gating network layers and the last Lambda inference layer are left trainable\n",
    "for l in model.layers:\n",
    "    print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "saveDir = \"./moe3Cifar10/\"\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(saveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "model = getNewestModel(model, saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 1.9518 - acc: 0.3236 - val_loss: 1.7278 - val_acc: 0.3900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.72783, saving model to ./moe3Cifar10/Cifar10_.01-1.73.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f076ab9d128>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x_train, y_train0,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test0),\n",
    "          callbacks=[es_cb, cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step\n",
      "[1.72783443069458, 0.39]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "mixture_loss_accuracy = model.evaluate(x_test, y_test0)\n",
    "print(mixture_loss_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amls_2",
   "language": "python",
   "name": "amls_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
